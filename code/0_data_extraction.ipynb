{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling video files : extracting frames from a video\n",
    "\n",
    "Given a video containing all the frames, we extract each individual frame to use as an RGB image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.handle_files import * #Contains makedir() and list_files()\n",
    "from functions.model_alignment import *\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_video(relative_filepath, extension):\n",
    "    \"\"\"\n",
    "    input : relative_filepath (str), folder containing the video\n",
    "            extension (str), extension of the video \n",
    "            \n",
    "    Extracts frames from a video and saves them.\n",
    "    Frames will be saved in a folder called frame in the same folder as the video,\n",
    "    So far, assumes that you have only one video in the folder.\n",
    "    ex:\n",
    "        extension is 'mp4'\n",
    "        video is contained in /directory/video/\n",
    "        frames will be saved in /directory/video/frames/\n",
    "    \"\"\"\n",
    "    #Getting the video filepath\n",
    "    video = list_files(relative_filepath, extension)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    target_directory = makedir(relative_filepath+'/frames/')\n",
    "    output_filename = target_directory+'frame_'\n",
    "    print(\"Reading frames and saving to folder.\")\n",
    "    i=0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read() #Test whether a frame was read correctly\n",
    "        if ret == False:\n",
    "            break\n",
    "        cv2.imwrite(output_filename+str(i)+'.jpg',frame)\n",
    "        i+=1\n",
    "    print(\"Done. A total of {} frames were saved.\".format(i))\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = '../worm_data/video/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target directory doesn't exist. Creating directory under /Users/pedrobedmar/MEGA/EPFL/ML/project2/cs-433-project-2-worm_brains/code/../worm_data/video//frames/\n",
      "Reading frames and saving to folder.\n",
      "Done. A total of 1715 frames were saved.\n"
     ]
    }
   ],
   "source": [
    "extract_frames_video(rel_path, '.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling .h5 files\n",
    "The .h5 files are structured as such : \n",
    "```\n",
    "├── file.h5\n",
    "    ├── 0\n",
    "    |   └── frame\n",
    "    └── 1\n",
    "    |   └── frame\n",
    "   ... \n",
    "    └── ...\n",
    "```\n",
    "Where each number correspond to the frame number.\n",
    "Within, we'll find a `frame` which contains the data for a given frame. They can be one channel (as is the case for the `file1`) or 3 channels (RGB, for `file2`). \n",
    "\n",
    "Each frame can be seen a stacks of 2D RGB images shape = (C, W, H). Thus, a `frame` is of shape **(C, W, H, Z)** where C is the channel, W and H the 2D dimensions (X and Y), and Z is the vertical Z-axis. \n",
    "\n",
    "To deal with the 3D component, we decided to use max project all the frames onto a 2D plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor, Resize, ToPILImage\n",
    "from PIL import Image\n",
    "\n",
    "PATH_h5 = '../worm_data/h5_data/'\n",
    "#Loading files\n",
    "file1 = h5.File(PATH_h5+'epfl3.h5')\n",
    "file2 = h5.File(PATH_h5+'more_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having explored the data located in file1, we've found those single channels, 112x112 images to be unusable due to their low resolution.\n",
    "\n",
    "Thus, only frames from file2 are extracted and used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting frames from files\n",
    "def extract_frames_h5(file, save_path, channel = 'rgb', resize=None):\n",
    "    \"\"\"\n",
    "    reads an h5 file and extracts all the frames within\n",
    "    Channel specify the channels to save\n",
    "    can be 'red', 'green' or 'rgb'.\n",
    "    paths are relative\n",
    "    \"\"\"\n",
    "    if resize: #using torch.transforms\n",
    "        res = Resize((resize,resize))\n",
    "    maxvalues = [1543, 1760]\n",
    "    #due to the structure, we keep only the files that are numeric\n",
    "    filenames = [x for x in file.keys() if x.isnumeric()]\n",
    "    filenames.sort(key=int) #Sort with key = int\n",
    "    \n",
    "    nb_channels = file['0/frame'].shape[0]\n",
    "    w_h = file['0/frame'].shape[1]\n",
    "    z = file['0/frame'].shape[3]\n",
    "    channel = channel.lower()\n",
    "    if ((nb_channels==1) and (channel=='rgb')):\n",
    "        print(\"No frame extracted. Exiting.\\nRGB specified, but only one color channel was found.\")\n",
    "        return\n",
    "    \n",
    "    PATH = makedir(save_path)\n",
    "    PATH = makedir(save_path+channel+'_frames')\n",
    "    print(\"Extracting {} frames.\".format(channel))\n",
    "    #For loop to extract all the frames\n",
    "    for index, number in enumerate(filenames):\n",
    "        name = number+'/frame'\n",
    "        frame = file[name]\n",
    "        #max projecting\n",
    "        \n",
    "        #creating RGB images with artificial blue \"background\" channel\n",
    "        if nb_channels==2 and channel=='rgb':\n",
    "            temp = torch.as_tensor(np.max(frame,axis=3),dtype=torch.float32) \n",
    "            blue = torch.full((1,512,512),0, dtype=torch.float32)\n",
    "            image_tensor = torch.cat((temp,blue))\n",
    "            #Normalizing to range [0,1]\n",
    "            image_tensor[0,...].div_(maxvalues[0])\n",
    "            image_tensor[1,...].div_(maxvalues[1])\n",
    "        \n",
    "        if channel!='rgb':\n",
    "            index = 0\n",
    "            if channel == 'green':\n",
    "                index = 1\n",
    "            image_tensor = torch.as_tensor(np.max(frame,axis=3),dtype=torch.float32)\n",
    "            if nb_channels!=1:\n",
    "                image_tensor[index,...].div_(maxvalues[index])\n",
    "                \n",
    "            image_tensor = image_tensor[index:index+1,...]\n",
    "    \n",
    "        if resize:\n",
    "            #Using this convoluted way due to some errors within pytorch\n",
    "            #with how it handles tensors/PILImage for Resize.\n",
    "            to_pili_image = ToPILImage()\n",
    "            image_tensor = to_pili_image(image_tensor)\n",
    "            image_tensor = ToTensor()(res(image_tensor))\n",
    "            \n",
    "        save_image(image_tensor, PATH+'/frame_'+number+'.jpg')\n",
    "            \n",
    "    print(\"Done. A total of {} frames were saved.\".format(len(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting rgb frames.\n",
      "Done. A total of 572 frames were saved.\n",
      "Extracting red frames.\n",
      "Done. A total of 572 frames were saved.\n",
      "Extracting green frames.\n",
      "Done. A total of 572 frames were saved.\n",
      "Extracting rgb frames.\n",
      "Done. A total of 572 frames were saved.\n",
      "Extracting red frames.\n",
      "Done. A total of 572 frames were saved.\n",
      "Extracting green frames.\n",
      "Done. A total of 572 frames were saved.\n"
     ]
    }
   ],
   "source": [
    "sizes = [240, 512]\n",
    "colors = ['rgb', 'red', 'green']\n",
    "\n",
    "#Extract frames in different ways and sizes.\n",
    "for size in sizes:\n",
    "    for col in colors:\n",
    "        if size == 240:\n",
    "            path = PATH_h5+str(size)+'/'\n",
    "        elif size == 512:\n",
    "            path = PATH_h5+str(size)+'/'\n",
    "        extract_frames_h5(file2, path, channel=col, resize=size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4aa635535829e595f413464b8d4b52eacf31c3326ae9850a263ad3e53fc82e1d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}