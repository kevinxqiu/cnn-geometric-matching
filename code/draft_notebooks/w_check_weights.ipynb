{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCLAIMER :: this notebook shouldn't work at all now after all the cleaning\n",
    "\n",
    "This was created to quickly get infos on the saved weights (model, loss, etc.)\n",
    "\n",
    "Not structured but just what I needed for quick checks, helped me sort the weights I've trained (which were a lot.)\n",
    "\n",
    "#### **As a result, most functions are not commented, written badly, and only works on windows given the filepaths returned by some functions** Do not attempt to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'util'))\n",
    "from handle_files import *\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "def load(path):\n",
    "    \"\"\"\n",
    "    Loads the checkpoint\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def stats(ckpt):\n",
    "    \"\"\"\n",
    "    gets the stats from a torch checkpoint\n",
    "    \"\"\"\n",
    "    epochs = ckpt['epoch']\n",
    "    args = ckpt['args']\n",
    "    bvl = ckpt['best_val_loss']\n",
    "    #print('EPOCH {}\\n'.format(epochs))\n",
    "    #print('Args', args)\n",
    "    #print('\\nBEST VAL LOSS', bvl)\n",
    "    return epochs, args, bvl\n",
    "    \n",
    "def full(path):\n",
    "    \"\"\"\n",
    "    Prints stats and returns them for the df\n",
    "    \"\"\"\n",
    "    #print('#############################')\n",
    "    #print('\\nWeight name : ', path)\n",
    "    x = load(path)\n",
    "    e,a,b = stats(x)\n",
    "    #print('--------------------------------\\n')\n",
    "    return e, a, b\n",
    "    \n",
    "def list_best(folderpath):\n",
    "    \"\"\"\n",
    "    full pipeline\n",
    "    \"\"\"\n",
    "    lw = list_files(folderpath+'*', '.tar')\n",
    "    df = pd.DataFrame()\n",
    "    for z in filter(lambda x: 'best' in x, lw):\n",
    "        e,a,b = full(z)\n",
    "        x = z.split('\\\\')\n",
    "        name = x[1]+'/'+x[2]\n",
    "        df = df.append({'wt': name, 'epoch':e,'args':a,'loss':b}, ignore_index=True)\n",
    "    return df.sort_values('loss')#.query('loss<=0.05')\n",
    "\n",
    "def list_all(folderpath):\n",
    "    \"\"\"\n",
    "    full pipeline\n",
    "    \"\"\"\n",
    "    lw = list_files(folderpath, '.tar')\n",
    "    df = pd.DataFrame()\n",
    "    for z in lw:\n",
    "        print(z)\n",
    "        e,a,b = full(z)\n",
    "        x = z.split('\\\\')\n",
    "        name = 'test'\n",
    "        df = df.append({'wt': name, 'epoch':e,'args':a,'loss':b}, ignore_index=True)\n",
    "    display(df)\n",
    "    return df.sort_values('loss').query('loss<=0.05')\n",
    "\n",
    "def check_arch(path):\n",
    "    \"\"\" Check to make sure I have the right weights with the right architecture names\"\"\"\n",
    "    x = load(path)\n",
    "    print(path)\n",
    "    for param_tensor in x['state_dict']:\n",
    "        print(param_tensor, \"\\t\", x['state_dict'][param_tensor].size())\n",
    "        \n",
    "def full_check(path, df, index):\n",
    "    check_arch(path+df.loc[index]['wt'])\n",
    "    print(\"\\n\",df.loc[index]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../trained_models/baseline_resnet\\affine_resnet_basefr.pth.tar\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at ..\\caffe2\\serialize\\inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at ..\\caffe2\\serialize\\inline_container.cc:132)\n(no backtrace available)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4e6f65fa2201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../trained_models/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#list_files(path+'baseline_resnet/','*.tar')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlist_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'baseline_resnet/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-73e70021e601>\u001b[0m in \u001b[0;36mlist_all\u001b[1;34m(folderpath)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-73e70021e601>\u001b[0m in \u001b[0;36mfull\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#print('#############################')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#print('\\nWeight name : ', path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m#print('--------------------------------\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-73e70021e601>\u001b[0m in \u001b[0;36mload\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mLoads\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\richi\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\richi\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: version_ <= kMaxSupportedFileFormatVersion INTERNAL ASSERT FAILED at ..\\caffe2\\serialize\\inline_container.cc:132, please report a bug to PyTorch. Attempted to read a PyTorch file with version 3, but the maximum supported version for reading is 2. Your PyTorch installation may be too old. (init at ..\\caffe2\\serialize\\inline_container.cc:132)\n(no backtrace available)"
     ]
    }
   ],
   "source": [
    "path = '../trained_models/'\n",
    "#list_files(path+'baseline_resnet/','*.tar')\n",
    "list_all(path+'baseline_resnet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../trained_models/wormbrain_basefr/affine_wormbrain1_basefr.pth.tar\n",
      "FeatureExtraction.model.0.weight \t torch.Size([32, 3, 5, 5])\n",
      "FeatureExtraction.model.0.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.weight \t torch.Size([32])\n",
      "FeatureExtraction.model.1.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_mean \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_var \t torch.Size([32])\n",
      "FeatureExtraction.model.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.3.weight \t torch.Size([64, 32, 5, 5])\n",
      "FeatureExtraction.model.3.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.weight \t torch.Size([64])\n",
      "FeatureExtraction.model.4.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_mean \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_var \t torch.Size([64])\n",
      "FeatureExtraction.model.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.7.weight \t torch.Size([128, 64, 5, 5])\n",
      "FeatureExtraction.model.7.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.weight \t torch.Size([128])\n",
      "FeatureExtraction.model.8.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_mean \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_var \t torch.Size([128])\n",
      "FeatureExtraction.model.8.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.10.weight \t torch.Size([256, 128, 5, 5])\n",
      "FeatureExtraction.model.10.bias \t torch.Size([256])\n",
      "FeatureExtraction.model.13.weight \t torch.Size([512, 256, 5, 5])\n",
      "FeatureExtraction.model.13.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.weight \t torch.Size([512])\n",
      "FeatureExtraction.model.14.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_mean \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_var \t torch.Size([512])\n",
      "FeatureExtraction.model.14.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.16.weight \t torch.Size([512, 512, 5, 5])\n",
      "FeatureExtraction.model.16.bias \t torch.Size([512])\n",
      "FeatureRegression.conv.0.weight \t torch.Size([128, 225, 7, 7])\n",
      "FeatureRegression.conv.0.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.weight \t torch.Size([128])\n",
      "FeatureRegression.conv.1.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_mean \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_var \t torch.Size([128])\n",
      "FeatureRegression.conv.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.conv.3.weight \t torch.Size([64, 128, 5, 5])\n",
      "FeatureRegression.conv.3.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.weight \t torch.Size([64])\n",
      "FeatureRegression.conv.4.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_mean \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_var \t torch.Size([64])\n",
      "FeatureRegression.conv.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.weight \t torch.Size([6, 1600])\n",
      "FeatureRegression.linear.bias \t torch.Size([6])\n",
      "../trained_models/wormbrain_basefr/affine_wormbrain1_basefr.pth.tar\n",
      "FeatureExtraction.model.0.weight \t torch.Size([32, 3, 5, 5])\n",
      "FeatureExtraction.model.0.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.weight \t torch.Size([32])\n",
      "FeatureExtraction.model.1.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_mean \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_var \t torch.Size([32])\n",
      "FeatureExtraction.model.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.3.weight \t torch.Size([64, 32, 5, 5])\n",
      "FeatureExtraction.model.3.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.weight \t torch.Size([64])\n",
      "FeatureExtraction.model.4.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_mean \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_var \t torch.Size([64])\n",
      "FeatureExtraction.model.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.7.weight \t torch.Size([128, 64, 5, 5])\n",
      "FeatureExtraction.model.7.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.weight \t torch.Size([128])\n",
      "FeatureExtraction.model.8.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_mean \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_var \t torch.Size([128])\n",
      "FeatureExtraction.model.8.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.10.weight \t torch.Size([256, 128, 5, 5])\n",
      "FeatureExtraction.model.10.bias \t torch.Size([256])\n",
      "FeatureExtraction.model.13.weight \t torch.Size([512, 256, 5, 5])\n",
      "FeatureExtraction.model.13.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.weight \t torch.Size([512])\n",
      "FeatureExtraction.model.14.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_mean \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_var \t torch.Size([512])\n",
      "FeatureExtraction.model.14.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.16.weight \t torch.Size([512, 512, 5, 5])\n",
      "FeatureExtraction.model.16.bias \t torch.Size([512])\n",
      "FeatureRegression.conv.0.weight \t torch.Size([128, 225, 7, 7])\n",
      "FeatureRegression.conv.0.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.weight \t torch.Size([128])\n",
      "FeatureRegression.conv.1.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_mean \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_var \t torch.Size([128])\n",
      "FeatureRegression.conv.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.conv.3.weight \t torch.Size([64, 128, 5, 5])\n",
      "FeatureRegression.conv.3.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.weight \t torch.Size([64])\n",
      "FeatureRegression.conv.4.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_mean \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_var \t torch.Size([64])\n",
      "FeatureRegression.conv.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.weight \t torch.Size([6, 1600])\n",
      "FeatureRegression.linear.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "check_arch('../trained_models/wormbrain_basefr/affine_wormbrain1_basefr.pth.tar')\n",
    "check_arch('../trained_models/wormbrain_basefr/affine_wormbrain1_basefr.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-64807ea37a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../trained_models/test_arch/fullset/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_test_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_test_arch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4505d64a2385>\u001b[0m in \u001b[0;36mlist_best\u001b[0;34m(folderpath)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'wt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.query('loss<=0.05')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5293\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5294\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5296\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "path = '../trained_models/test_arch/fullset/'\n",
    "df_test_arch = list_best(path)\n",
    "df_test_arch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trained_models/test_arch/fullset/best_newFR/best_rgb512_aug_TPS_test_2_newFR_dropout015xd_tps_grid_losstest_2.pth.tar\n",
      "FeatureExtraction.model.0.weight \t torch.Size([32, 3, 5, 5])\n",
      "FeatureExtraction.model.0.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.weight \t torch.Size([32])\n",
      "FeatureExtraction.model.1.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_mean \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_var \t torch.Size([32])\n",
      "FeatureExtraction.model.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.3.weight \t torch.Size([64, 32, 5, 5])\n",
      "FeatureExtraction.model.3.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.weight \t torch.Size([64])\n",
      "FeatureExtraction.model.4.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_mean \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_var \t torch.Size([64])\n",
      "FeatureExtraction.model.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.7.weight \t torch.Size([128, 64, 5, 5])\n",
      "FeatureExtraction.model.7.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.weight \t torch.Size([128])\n",
      "FeatureExtraction.model.8.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_mean \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_var \t torch.Size([128])\n",
      "FeatureExtraction.model.8.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.10.weight \t torch.Size([256, 128, 5, 5])\n",
      "FeatureExtraction.model.10.bias \t torch.Size([256])\n",
      "FeatureExtraction.model.13.weight \t torch.Size([512, 256, 5, 5])\n",
      "FeatureExtraction.model.13.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.weight \t torch.Size([512])\n",
      "FeatureExtraction.model.14.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_mean \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_var \t torch.Size([512])\n",
      "FeatureExtraction.model.14.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.16.weight \t torch.Size([512, 512, 5, 5])\n",
      "FeatureExtraction.model.16.bias \t torch.Size([512])\n",
      "FeatureRegression.conv.0.weight \t torch.Size([128, 225, 7, 7])\n",
      "FeatureRegression.conv.0.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.weight \t torch.Size([128])\n",
      "FeatureRegression.conv.1.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_mean \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_var \t torch.Size([128])\n",
      "FeatureRegression.conv.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.conv.3.weight \t torch.Size([64, 128, 5, 5])\n",
      "FeatureRegression.conv.3.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.weight \t torch.Size([64])\n",
      "FeatureRegression.conv.4.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_mean \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_var \t torch.Size([64])\n",
      "FeatureRegression.conv.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.0.weight \t torch.Size([1024, 1600])\n",
      "FeatureRegression.linear.0.bias \t torch.Size([1024])\n",
      "FeatureRegression.linear.2.weight \t torch.Size([1024])\n",
      "FeatureRegression.linear.2.bias \t torch.Size([1024])\n",
      "FeatureRegression.linear.2.running_mean \t torch.Size([1024])\n",
      "FeatureRegression.linear.2.running_var \t torch.Size([1024])\n",
      "FeatureRegression.linear.2.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.4.weight \t torch.Size([512, 1024])\n",
      "FeatureRegression.linear.4.bias \t torch.Size([512])\n",
      "FeatureRegression.linear.6.weight \t torch.Size([512])\n",
      "FeatureRegression.linear.6.bias \t torch.Size([512])\n",
      "FeatureRegression.linear.6.running_mean \t torch.Size([512])\n",
      "FeatureRegression.linear.6.running_var \t torch.Size([512])\n",
      "FeatureRegression.linear.6.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.8.weight \t torch.Size([256, 512])\n",
      "FeatureRegression.linear.8.bias \t torch.Size([256])\n",
      "FeatureRegression.linear.10.weight \t torch.Size([256])\n",
      "FeatureRegression.linear.10.bias \t torch.Size([256])\n",
      "FeatureRegression.linear.10.running_mean \t torch.Size([256])\n",
      "FeatureRegression.linear.10.running_var \t torch.Size([256])\n",
      "FeatureRegression.linear.10.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.12.weight \t torch.Size([128, 256])\n",
      "FeatureRegression.linear.12.bias \t torch.Size([128])\n",
      "FeatureRegression.linear.14.weight \t torch.Size([128])\n",
      "FeatureRegression.linear.14.bias \t torch.Size([128])\n",
      "FeatureRegression.linear.14.running_mean \t torch.Size([128])\n",
      "FeatureRegression.linear.14.running_var \t torch.Size([128])\n",
      "FeatureRegression.linear.14.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.16.weight \t torch.Size([64, 128])\n",
      "FeatureRegression.linear.16.bias \t torch.Size([64])\n",
      "FeatureRegression.linear.18.weight \t torch.Size([64])\n",
      "FeatureRegression.linear.18.bias \t torch.Size([64])\n",
      "FeatureRegression.linear.18.running_mean \t torch.Size([64])\n",
      "FeatureRegression.linear.18.running_var \t torch.Size([64])\n",
      "FeatureRegression.linear.18.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.20.weight \t torch.Size([18, 64])\n",
      "FeatureRegression.linear.20.bias \t torch.Size([18])\n",
      "\n",
      " Namespace(batch_size=16, dataset_csv_path='training_data/rgb512_augmented-random', dataset_image_path='datasets/rgb512_augmented/', fe_finetune_params=[''], feature_extraction_cnn='test_2', feature_extraction_last_layer='', four_point_hom=True, fr_channels=[225, 128, 64], fr_kernel_sizes=[7, 5, 5], geometric_model='tps', image_size=512, log_dir='', log_interval=100, lr=0.003667, lr_max_iter=1000, lr_scheduler=True, matching_type='correlation', model='', momentum=0.94, normalize_matches=True, num_epochs=50, num_workers=4, occlusion_factor=0, pretrained=True, random_alpha=0.16666666666666666, random_s=0.5, random_sample=True, random_t=0.5, random_t_tps=0.4, seed=1, test_dataset_size=0, train_bn=True, train_dataset_size=0, train_fe=True, train_fr=True, trained_model_dir='./trained_models/test_arch/fullset/', trained_model_fn='TPS_test_2_newFR_dropout015xd', training_dataset='rgb512_aug', update_bn_buffers=False, use_mse_loss=False, weight_decay=0)\n"
     ]
    }
   ],
   "source": [
    "full_check(path,df_test_arch, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>args</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Namespace(batch_size=16, dataset_csv_path='tra...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>affineWB1_simplerScheduler1e7/best_rgb512_aug_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Namespace(batch_size=16, dataset_csv_path='tra...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>tpsWB1_simplerAnother/best_rgb512_aug_tpsWB1_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Namespace(batch_size=16, dataset_csv_path='tra...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.029655</td>\n",
       "      <td>tpsWB1_simpler/best_rgb512_aug_tpsWB1_simpler_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Namespace(batch_size=16, dataset_csv_path='tra...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>tpsWB1_simplerLastTry/best_rgb512_aug_tpsWB1_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Namespace(batch_size=16, dataset_csv_path='tra...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>tpsWB1_simplerScheduler1e7/best_rgb512_aug_tps...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                args  epoch      loss  \\\n",
       "0  Namespace(batch_size=16, dataset_csv_path='tra...   40.0  0.008201   \n",
       "1  Namespace(batch_size=16, dataset_csv_path='tra...   31.0  0.028545   \n",
       "4  Namespace(batch_size=16, dataset_csv_path='tra...   24.0  0.029655   \n",
       "2  Namespace(batch_size=16, dataset_csv_path='tra...   21.0  0.031329   \n",
       "3  Namespace(batch_size=16, dataset_csv_path='tra...   23.0  0.031951   \n",
       "\n",
       "                                                  wt  \n",
       "0  affineWB1_simplerScheduler1e7/best_rgb512_aug_...  \n",
       "1  tpsWB1_simplerAnother/best_rgb512_aug_tpsWB1_s...  \n",
       "4  tpsWB1_simpler/best_rgb512_aug_tpsWB1_simpler_...  \n",
       "2  tpsWB1_simplerLastTry/best_rgb512_aug_tpsWB1_s...  \n",
       "3  tpsWB1_simplerScheduler1e7/best_rgb512_aug_tps...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpler = './trained_models/simpler/'\n",
    "df_simpler = list_best(simpler)\n",
    "df_simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trained_models/simpler/tpsWB1_simplerAnother/best_rgb512_aug_tpsWB1_simplerAnother_tps_grid_losswormbrain_1.pth.tar\n",
      "FeatureExtraction.model.0.weight \t torch.Size([32, 3, 5, 5])\n",
      "FeatureExtraction.model.0.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.weight \t torch.Size([32])\n",
      "FeatureExtraction.model.1.bias \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_mean \t torch.Size([32])\n",
      "FeatureExtraction.model.1.running_var \t torch.Size([32])\n",
      "FeatureExtraction.model.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.3.weight \t torch.Size([64, 32, 5, 5])\n",
      "FeatureExtraction.model.3.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.weight \t torch.Size([64])\n",
      "FeatureExtraction.model.4.bias \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_mean \t torch.Size([64])\n",
      "FeatureExtraction.model.4.running_var \t torch.Size([64])\n",
      "FeatureExtraction.model.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.7.weight \t torch.Size([128, 64, 5, 5])\n",
      "FeatureExtraction.model.7.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.weight \t torch.Size([128])\n",
      "FeatureExtraction.model.8.bias \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_mean \t torch.Size([128])\n",
      "FeatureExtraction.model.8.running_var \t torch.Size([128])\n",
      "FeatureExtraction.model.8.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.10.weight \t torch.Size([256, 128, 5, 5])\n",
      "FeatureExtraction.model.10.bias \t torch.Size([256])\n",
      "FeatureExtraction.model.13.weight \t torch.Size([512, 256, 5, 5])\n",
      "FeatureExtraction.model.13.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.weight \t torch.Size([512])\n",
      "FeatureExtraction.model.14.bias \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_mean \t torch.Size([512])\n",
      "FeatureExtraction.model.14.running_var \t torch.Size([512])\n",
      "FeatureExtraction.model.14.num_batches_tracked \t torch.Size([])\n",
      "FeatureExtraction.model.16.weight \t torch.Size([512, 512, 5, 5])\n",
      "FeatureExtraction.model.16.bias \t torch.Size([512])\n",
      "FeatureRegression.conv.0.weight \t torch.Size([128, 225, 7, 7])\n",
      "FeatureRegression.conv.0.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.weight \t torch.Size([128])\n",
      "FeatureRegression.conv.1.bias \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_mean \t torch.Size([128])\n",
      "FeatureRegression.conv.1.running_var \t torch.Size([128])\n",
      "FeatureRegression.conv.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.conv.3.weight \t torch.Size([64, 128, 5, 5])\n",
      "FeatureRegression.conv.3.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.weight \t torch.Size([64])\n",
      "FeatureRegression.conv.4.bias \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_mean \t torch.Size([64])\n",
      "FeatureRegression.conv.4.running_var \t torch.Size([64])\n",
      "FeatureRegression.conv.4.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.0.weight \t torch.Size([512, 1600])\n",
      "FeatureRegression.linear.0.bias \t torch.Size([512])\n",
      "FeatureRegression.linear.1.weight \t torch.Size([512])\n",
      "FeatureRegression.linear.1.bias \t torch.Size([512])\n",
      "FeatureRegression.linear.1.running_mean \t torch.Size([512])\n",
      "FeatureRegression.linear.1.running_var \t torch.Size([512])\n",
      "FeatureRegression.linear.1.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.4.weight \t torch.Size([128, 512])\n",
      "FeatureRegression.linear.4.bias \t torch.Size([128])\n",
      "FeatureRegression.linear.6.weight \t torch.Size([128])\n",
      "FeatureRegression.linear.6.bias \t torch.Size([128])\n",
      "FeatureRegression.linear.6.running_mean \t torch.Size([128])\n",
      "FeatureRegression.linear.6.running_var \t torch.Size([128])\n",
      "FeatureRegression.linear.6.num_batches_tracked \t torch.Size([])\n",
      "FeatureRegression.linear.8.weight \t torch.Size([18, 128])\n",
      "FeatureRegression.linear.8.bias \t torch.Size([18])\n",
      "\n",
      " Namespace(batch_size=16, dataset_csv_path='training_data/rgb512_augmented-random', dataset_image_path='datasets/rgb512_augmented/', fe_finetune_params=[''], feature_extraction_cnn='wormbrain_1', feature_extraction_last_layer='', feature_regression='simpler', four_point_hom=True, fr_channels=[225, 128, 64], fr_dropout=0.2, fr_kernel_sizes=[7, 5, 5], geometric_model='tps', image_size=512, log_dir='', log_interval=100, lr=0.00667, lr_max_iter=3000, lr_scheduler=True, matching_type='correlation', model='', momentum=0.92, normalize_matches=True, num_epochs=40, num_workers=4, occlusion_factor=0, pretrained=True, random_alpha=0.16666666666666666, random_s=0.5, random_sample=True, random_t=0.5, random_t_tps=0.4, seed=1, test_dataset_size=0, train_bn=True, train_dataset_size=0, train_fe=True, train_fr=True, trained_model_dir='./trained_models/simpler/', trained_model_fn='tpsWB1_simplerAnother', training_dataset='rgb512_aug', update_bn_buffers=False, use_mse_loss=False, weight_decay=0)\n"
     ]
    }
   ],
   "source": [
    "full_check(simpler,df_simpler,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
